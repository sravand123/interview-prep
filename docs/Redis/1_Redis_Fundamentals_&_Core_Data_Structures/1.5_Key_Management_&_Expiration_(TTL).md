---
topic: Redis
section: Redis Fundamentals & Core Data Structures
subtopic: Key Management & Expiration (TTL)
level: Beginner
---

## Key Management & Expiration (TTL)
### Core Concepts

*   **Key Expiration (TTL - Time To Live):** A fundamental Redis mechanism to automatically delete keys after a specified period. This is crucial for:
    *   **Cache Management:** Storing temporary data (e.g., session tokens, temporary results) that naturally expires.
    *   **Memory Efficiency:** Preventing unbounded memory growth by ensuring old or stale data is automatically removed.
    *   **Data Consistency (Eventual):** Ensuring cached data doesn't diverge too much from the source of truth over time.
    *   **Rate Limiting/Throttling:** Using keys with short TTLs to track access counts over time windows.

*   **Key Management:** Refers to the broader set of operations for controlling the lifecycle of keys, including setting, updating, querying expiration, and making keys persistent.

### Key Details & Nuances

*   **Expiration Granularity:** TTL can be set in seconds (`EXPIRE`, `EX`, `EXPIREAT`) or milliseconds (`PEXPIRE`, `PX`, `PEXPIREAT`).
*   **Lazy vs. Active Expiration:**
    *   **Lazy Expiration:** Keys are removed only when an attempt is made to *access* them (e.g., `GET`, `HGETALL`). This saves CPU cycles but means expired keys might temporarily reside in memory.
    *   **Active Expiration:** Redis periodically checks a random sample of keys with TTLs to identify and remove expired ones. This process runs in the background and is configurable.
        *   By default, Redis checks 20 random keys 10 times per second, removing expired ones. If more than 25% of the sampled keys are expired, it repeats the process.
*   **Eviction Policies (when memory limit is reached):** While TTL handles time-based expiration, eviction policies define what happens when Redis runs out of memory *and* new keys need to be added.
    *   `noeviction`: New writes fail if memory limit is reached.
    *   `allkeys-lru`: Evicts the least recently used keys, regardless of TTL.
    *   `volatile-lru`: Evicts the least recently used keys *that have a TTL set*.
    *   `allkeys-random`: Evicts random keys, regardless of TTL.
    *   `volatile-random`: Evicts random keys *that have a TTL set*.
    *   `allkeys-lfu`: Evicts the least frequently used keys, regardless of TTL.
    *   `volatile-lfu`: Evicts the least frequently used keys *that have a TTL set*.
    *   `volatile-ttl`: Evicts keys with the shortest remaining TTL.
    *   **Crucial Distinction:** TTL is about *time-based* removal; eviction policies are about *memory-pressure-based* removal. They can work in tandem.
*   **Persistence Interaction:**
    *   **RDB (Snapshotting):** Expired keys are not saved to the RDB file. Keys that expire *while* an RDB save is in progress are still considered expired and won't be saved if their TTL runs out before the save completes.
    *   **AOF (Append-Only File):** When an expired key is removed (either lazily or actively), a `DEL` command is appended to the AOF. This ensures consistency during AOF replay.

### Practical Examples

**Redis CLI Commands:**

```sh
# Set a key with a TTL of 60 seconds
SET mykey "some_value" EX 60

# Set a key with a TTL of 1000 milliseconds (1 second)
SET anotherkey "another_value" PX 1000

# Set an expiration for an existing key to 30 seconds from now
EXPIRE mykey 30

# Check remaining TTL in seconds (-2 if key does not exist, -1 if key exists but no TTL)
TTL mykey

# Check remaining TTL in milliseconds
PTTL mykey

# Remove the TTL, making the key persistent
PERSIST mykey

# Atomically set a key and its TTL (preferred over separate SET and EXPIRE)
SETEX newkey 120 "value_with_ttl"
```

**TypeScript/Node.js using `node-redis`:**

```typescript
import { createClient } from 'redis';

async function manageKeys() {
  const client = createClient();
  await client.connect();

  // Set a key with a TTL of 60 seconds
  await client.set('session:user123', '{"user_id":123,"login_time":"..."}', {
    EX: 60, // Set expiry in seconds
  });
  console.log('Key set with 60s TTL.');

  // Get TTL in seconds
  const ttl = await client.ttl('session:user123');
  console.log(`TTL for session:user123: ${ttl} seconds`);

  // Update TTL for an existing key to 300 seconds
  await client.expire('session:user123', 300);
  console.log('TTL updated to 300s.');

  // Make the key persistent (remove TTL)
  await client.persist('session:user123');
  console.log('Key made persistent.');

  // Attempt to get TTL again (should be -1)
  const newTtl = await client.ttl('session:user123');
  console.log(`New TTL for session:user123: ${newTtl} seconds (should be -1 for persistent key)`);

  await client.disconnect();
}

manageKeys().catch(console.error);
```

### Common Pitfalls & Trade-offs

*   **Atomic Operations:** Using separate `SET` and `EXPIRE` commands can lead to race conditions if the application crashes or a network partition occurs between the two commands, potentially leaving a key without an intended TTL or vice-versa. Always prefer atomic commands like `SETEX` or the `SET key value EX seconds` syntax.
*   **TTL Granularity:** Setting very short TTLs (e.g., milliseconds) for non-critical data can lead to high churn and increased background processing for expiration. Conversely, very long TTLs can reduce the effectiveness of caching and lead to stale data. Choose a TTL appropriate for the data's staleness tolerance.
*   **Memory Pressure Without TTLs:** Relying *solely* on TTLs for memory management is insufficient. If new data is added faster than old data expires, Redis can still run out of memory. This is where proper eviction policies (`maxmemory-policy`) are critical to complement TTLs.
*   **`PERSIST` Overuse:** Indiscriminately making keys persistent negates the memory-saving benefits of TTLs. Use `PERSIST` only when a key, initially set with a TTL, truly needs to become permanent.
*   **Client-Side TTL Management:** Do not implement TTL logic in your application code; always rely on Redis's native expiration. Client-side TTLs are prone to clock drift, race conditions, and increased complexity.

### Interview Questions

1.  **Explain the difference between Redis's key expiration (TTL) and its eviction policies. When would you use one over the other, or both?**
    *   **Answer:** TTL is a time-based mechanism to automatically delete keys after a set duration, ensuring data freshness and limiting specific key lifespans. Eviction policies, on the other hand, are memory-pressure-based: they define how Redis sheds keys to stay within a configured `maxmemory` limit when new writes occur. You use TTL for predictable data invalidation (e.g., session tokens). You use eviction policies to prevent OOM errors when the cache fills up. Often, you use both: TTLs handle time-based cleanup, and an eviction policy (e.g., `volatile-lru`) provides a fallback for memory pressure, prioritizing eviction of keys *with* TTLs first.
2.  **Describe how Redis ensures expired keys are actually removed from memory. Is it always instantaneous?**
    *   **Answer:** Redis employs two main mechanisms:
        *   **Lazy Expiration:** A key is removed only when it's explicitly accessed (e.g., via `GET`, `HGETALL`). If an expired key is never accessed, it remains in memory until active expiration or an eviction policy handles it.
        *   **Active Expiration:** Redis periodically (e.g., 10 times per second) samples a small number of keys that have a TTL set and removes any that have expired. This proactive cleanup helps manage memory even for unaccessed keys.
    *   It is **not always instantaneous**. Due to lazy expiration and the sampling nature of active expiration, an expired key might reside in memory for a short period after its TTL has passed.
3.  **You are designing a rate-limiting system using Redis. How would you leverage TTL and what atomic commands would you use to ensure correctness?**
    *   **Answer:** I would use Redis hashes or simple keys, setting a TTL for the time window. For a per-user, per-minute rate limit:
        1.  Use `INCR` or `HINCRBY` to increment a counter for a specific user within the current minute's window (e.g., `rate_limit:user123:2023-10-27-14:30`).
        2.  Atomically set the TTL for this key using `EXPIRE` **immediately after** the first `INCR` operation for that key. This `EXPIRE` should be set to the end of the current minute plus a small buffer to account for potential clock skew or network latency (e.g., 60 seconds from the start of the minute).
        3.  The critical part is ensuring the `INCR` and `EXPIRE` are either atomic or the `EXPIRE` happens on the *first* increment. A better approach for many rate limits is to use `SET key value EX seconds NX` if the value is just `1` (first hit), then `INCR` on subsequent hits. For counters, ensure the TTL is set only once for the window. `EXPIRE` command can be used on an existing key after an `INCR`. If using `INCR` on a key that doesn't exist, its initial value is 0 before incrementing to 1.
4.  **What happens to keys with TTLs during Redis persistence operations (RDB and AOF)?**
    *   **Answer:**
        *   **RDB (Snapshotting):** When an RDB snapshot is saved, only keys that are *not* expired at the moment of saving are included in the RDB file. If a key expires during the RDB save process, it will not be saved.
        *   **AOF (Append-Only File):** When a key expires and is removed (either via lazy or active expiration), Redis appends a `DEL` command to the AOF. This ensures that when the AOF is replayed during recovery, the key is correctly removed, maintaining consistency.
5.  **You have a Redis instance approaching its `maxmemory` limit. How would you configure `maxmemory-policy` in conjunction with keys that have TTLs to optimize for caching most valuable data?**
    *   **Answer:** To optimize for caching valuable data while respecting TTLs, I would choose an eviction policy from the `volatile-*` family.
    *   **`volatile-lru`:** This is often a good default. It evicts the least recently used keys *that have a TTL set*. This is efficient because it targets data designed to be temporary, and the LRU algorithm is generally effective for caching.
    *   **`volatile-lfu`:** If access patterns show clear "hot" vs. "cold" data and you want to prioritize keeping frequently accessed temporary data, LFU can be better than LRU.
    *   **`volatile-ttl`:** This policy evicts keys with the shortest remaining TTL. It's useful if you want to ensure that keys closest to their natural expiration are the first to be removed under memory pressure, effectively "accelerating" their expiration.
    *   The choice depends on the specific access patterns and data importance, but `volatile-lru` is a strong general-purpose choice.